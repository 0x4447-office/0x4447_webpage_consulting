[
  {
    "company_name": "Atkins",
    "description": "Expert Sinus Care. Your Solution for Sinus Problems",
    "logo_name": "atkinssinus.png",
    "color": "#fcb555",
    "slug": "atkins",
    "url": {
      "name": "atkinssinus.com",
      "href": "https://www.atkinssinus.com"
    },
    "subtitle": "Video editing rig in the cloud with Nvidia Cuda.",
    "opinion": "His knowledge of Amazon Web services, all of their features and capabilities is amazing. He is incredibly responsive. He gives me daily updates in great detail. His ingenuity is unparalleled. I would work with him again in a heartbeat. If you have anything at all that needs to be run on Amazon Web services or any of their affiliated businesses this is the person for you.",
    "author": "James Atkins, CEO.",
    "content": "<p>The clinic Atkins Sinus are experts aiding in fixing sinus problems. They are always at the lookout for technologies that can help them provide better care and share knowledge and information to their patients. They decided to invest in making videos showcasing operations, insight in the most common problems and generally helpful information for anyone interested in listening. </p> <p>Turns out that editing videos is not as easy as it seems, you need a powerful machine to edit 4k videos and then render them in the final form; their office computers did struggle with this task. Dr. James decided to see if it is possible to host a video editing rig in the Cloud, and tasked me to research if this was even possible.</p> <p>Since AWS has CUDA cards by Nvidia I decided to setup a Windows Server instance with Adobe Premiere. For secure access and an easy way to upload and download video files I setup a Samba server within the private subnet of the video editing rig. This was tied it all together with a OpenVPN server to allow anyone in the office to access the private resources. </p> <p>With this solution Dr. James Atkins was able to connect to the VPN, mount the Samba server on his local machine, upload files, edit them in the cloud and download the rendered videos with ease. </p> <p>As an addition to preserve costs, I made a AWS Lambda ran every 30 minutes and checked the CPU load on the Windows Server. If the percentage was bellow 4% the lambda was set to shut down the server, and thus preserve costs. </p> <p>With a simple desktop app anyone in the office was able to turn on the server when needed and thus the clinic was being charged for the video editing rig only when they were using it.</p>"
  },
  {
    "company_name": "Applied Behavioral Finance",
    "description": "Highly customized and precise retirement plans.",
    "logo_name": "applied_behavioral_finance.png",
    "color": "#209e49",
    "slug": "applied-behavioral-finance",
    "url": {
      "name": "appliedbehavioralfinance.com",
      "href": "https://appliedbehavioralfinanceinc.com"
    },
    "subtitle": "Fintech portal for Advisors and Investors based 100% on Serverless.",
    "content": "<p>Applied Behavior Finance is a fintech product built 100% on top of the AWS Serverless technology. The reason for this approach was to preserve costs in the initial stages when the project was gaining popularity, and then as more user were signing up the client didn't want to have to worry about scalability, managing servers and worrying that something might stop working due to occasional spikes.</p> <p>The whole project was built using:</p> <ul> <li>AWS Lambda</li> <li>DynamoDB</li> <li>DynamoDB Triggers</li> <li>CloudWatch</li> <li>CloudWatch Events</li> <li>SQS</li> <li>API Gateway</li> <li>CloudFront</li> <li>Route53</li> <li>CodePipeline</li> <li>CodeBuild</li> <li>S3</li> </ul> <p>Everything was tied together using multiple CloudFormation files to stay organized and easily track any changes over time. This provides the added benefit of being able to deploy the same stack in different environments.</p> <p>In addition the developers got a simple to use environment to work in since they didn't have to worry about the infrastructure. Using CodePipeline each GitHub repository was set to auto-deployment any time new code was being added to selected branches. This way developer could focus on what they know best, and let the stack do its thing.</p>"
  },
  {
    "company_name": "Vocatales",
    "description": "Discover the wondrous new world of storytelling.",
    "logo_name": "vocatales.png",
    "color": "#FF5A5F",
    "slug": "vocatales",
    "url": {
      "name": "vocatales.com",
      "href": "https://www.vocatales.com/"
    },
    "subtitle": "Setup AWS with best practices in mind to speed up development.",
    "opinion": "David is a master DevOps Solutions Architect â€“ one of the best on this platform. His understanding of the AWS ecosystem is just exemplary and the level of automation he helped me achieve in such a short amount of time is simply amazing. I will definitely return with more projects in future, and highly recommend David to anyone looking to add an accomplished solutions architect to your team.",
    "author": "G. G, CEO.",
    "content": "<p>The CEO of Vocatales created an educational platform that aims to reimagine vocabulary to aid learning. The setup was already running in AWS as a NVP but since the site was gaining popularity the project needed an overhaul from the AWS infrastructure stand point. </p> <p>The CEO of the company asked me if I could help updating the stack design to bring it up to AWS best practices, and set it up for auto deployment and scalability. </p> <p>Since this is my area of expertise I started working on the project immediately by creating a new CloudFormation file that included CodePipeline and CodeBuild for auto deployment. I then worked on an ECS setup to deliver the containers of the project in a auto scaling fashion. </p> <p>I also helped the CEO understand AWS better by answering all of his questions and mentoring him about all the AWS best practices.</p>"
  },
  {
    "company_name": "Webcorp",
    "description": "The Job Application... Reinvented",
    "logo_name": "webcorp.png",
    "color": "#38a2ff",
    "slug": "webcorp",
    "url": {
      "name": "webcorp.com",
      "href": "https://webcorp.com/"
    },
    "subtitle": "Serverless solution to scan files in S3 with ClamAV.",
    "permalink": "webcorp",
    "content": "<p>The Webcorp company specializes in recruiting candidates across the world, and they were looking for a serverless solution to scan incoming CVs and files from candidates for viruses. </p> <p>I helped them by creating a solution using two Lambda functions. One was responsible for pulling on a daily basis a new virus definition from a database, and the other was responsible for scanning the incoming files in S3. The scanning process was done all in memory which allowed not only the project to scale up and down as needed thanks to the serverless nature of Lambda, but the code itself was wirtten in a way that it was able to take advantage of future updateds to the lambda. If the lambda was gaining more memory the scanning process was able to handle bigger files.</p> <p>The project started by beeing able to handle 2GB files, and as of writing this, it can handle 10GB files. The only thing the client has to do, is to update the lambda configuration to allow it the access to more memory, and the code will just take advantage of the newly avaiable memory.</p> "
  },
  {
    "company_name": "Security 7",
    "description": "Managed Cybersecurity Services.",
    "logo_name": "security7.svg",
    "color": "#79bc5d",
    "slug": "security-7",
    "url": {
      "name": "security7.net",
      "href": "https://www.security7.net/"
    },
    "subtitle": "Setup a serverless pipeline to convert security logs at scale.",
    "opinion": "David's work was top notch! His code was well written, incredibly well documented and very thorough. His knowledge of AWS platform was exceptional and he was able to build a robust open source set of Lambda functions for us that we intend to expand upon in the future.",
    "author": "Brian Thomas, CTO.",
    "content": "<p>Security7 is a company focused on helping other businesses secure their systems by monitoring their infrastructure and logs, while auditing and providing consultation about best practices.</p> <p>One of Security7's main focuses is log analysis, and they were looking for a serverless solution to standardize the format in which those logs were being proceed since the data was coming from multiple sources, in multiple formats and data structures.</p> <p>The whole setup was composed of an API Gateway endpoint and one lambda, that had multiple modules to handle the different incoming formats. This aspect was crucial to allow flexibility and extendibility of the code for any future changes in the log formats.</p> <p>The whole project was codified in a CloudFormation file that allowed the client to deploy the solution across multiple accounts with ease.</p>"
  },
  {
    "company_name": "Sequr",
    "description": "Cloud based physical-access control.",
    "logo_name": "sequr.png",
    "color": "#478eca",
    "slug": "sequr",
    "url": {
      "name": "sequr.io",
      "href": "https://www.sequr.io/"
    },
    "subtitle": "Write a server for IoT Devices and convert custom protocol in to a simple to use API.",
    "content": "<p>Sequr (now part of Genea) is a Access Control product targeted at managing access to physical buildings like office spaces and sky skyscrapers. The company had a humble beginning where it started managing access in gated communities with a SMS solution to give temporary access to guests of the owners.</p> <p>Soon they wanted to extend their offering by managing access to bigger buildings using the world renowned HID system. The only problem was the complexity of the product. </p> <p>The access control system was designed in the late 90's. It communicated over a socket connection and with a very oddly designed protocol.</p> <p>I was tasked to put a modern RESTfull API in front of the device to allow any developer to easily interact with the device anywhere in the world. The solution came down to a custom NodeJS server where the devices would connect, and the custom server would accept incoming API request and translate them on the fly in the archaic protocol to be sent to the selected device.</p> <p>The solution is working still to this day allowing the client to keep growing, and managing more buildings without the need of any type of modification to the architecture.</p>"
  },
  {
    "company_name": "Marine Central",
    "description": "Marine Services Database for all sailors.",
    "logo_name": "marinecentral.jpg",
    "color": "#8ac4e9",
    "slug": "marine-central",
    "url": {
      "name": "marinecentral.com",
      "href": "https://marinecentral.com/"
    },
    "subtitle": "Reorganize the whole AWS infrastructure and stabilize the product.",
    "content": "<p>The Marine Central website is a catalog of services related to the marine world, where you can rent boats, find a captain or crew and find a service related to the marine world.</p> <p>The website was up and running already but was struggling with reliability. The site was often down, and was not scaling properly in AWS. My job was to make the site stable, and help with code quality since every time the team added a new feature, they would unintentionally break something else.</p> <p>To solve these two problems I put the code in a Docker container and use AWS ECS to host those containers with the correct auto scaling setup. The goal of this solution was to fix auto scaling but also prevent the developers from having direct access to the server and directly fixing issues within the production server. This way they were forced to test their work using a Docker container in their local environment before pushing the changes in to the world. It took the developers few weeks to get used to the idea but eventually they recognized the benefit, and were happy to work with the added security.</p> <p>After this point the client had less worries about new features breaking other ones, and he had the peace of mind knowing that the website would grow with the new influx of clients and customers.</p>"
  },
  {
    "company_name": "Tonic HQ",
    "description": "Building your staffing business through technology.",
    "logo_name": "tonichq.png",
    "color": "#18afa3",
    "slug": "tonic-hq",
    "url": {
      "name": "tonichq.com",
      "href": "https://tonichq.com/"
    },
    "subtitle": "Create many different Serverless solutions to manage 3th party services.",
    "opinion": "A pleasure to work with. Smart, a good communicator and gets the job done. An educator at heart, he's a stickler for the details and that's much appreciated. He wants to do things the right way, not the quickest way. Looking forward to working on future projects.",
    "author": "Dan Donathan, CEO.",
    "content": "<p>TonicHQ, a technology staffing company, was looking for a serverless solution to help them automate a lot of small procesess in the company workflow that were repetitive, prone to mistakes and plain old boring to keep doing manually. </p> <p>The solution was to use API Gateway, Lambda, S3 and a CloudFormation file to create small self contained solution that would specialize in doing one small task for the befit of the whole project. </p> <p>After automating dozens of dozens of these tasks the client was left with a solution that was easy to extend. Since he was technical enough himself, and the code was well organized and had lots of comments, he was able to apply small changes to match the slight adjustments in the work flow. With auto-deployment enabled, he didn't have to worry about how to push the new code the lambda. The whole process was automated.</p> "
  }
]
